{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-01-20T22:39:45.500482Z","iopub.status.busy":"2025-01-20T22:39:45.500092Z","iopub.status.idle":"2025-01-20T22:39:45.801795Z","shell.execute_reply":"2025-01-20T22:39:45.800884Z","shell.execute_reply.started":"2025-01-20T22:39:45.500449Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/data-t/data/train_20_DLL_ass4.pkl\n","/kaggle/input/data-t/data/test_20_DLL_ass4.pkl\n","/kaggle/input/data-t/data/dummy_20_DLL_ass4 (1).pkl\n","/kaggle/input/data-t/data/valid_20_DLL_ass4.pkl\n"]}],"source":["##INNOCENTKISOKA#\n","\n","\n","# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:45.803400Z","iopub.status.busy":"2025-01-20T22:39:45.802930Z","iopub.status.idle":"2025-01-20T22:39:48.064493Z","shell.execute_reply":"2025-01-20T22:39:48.063792Z","shell.execute_reply.started":"2025-01-20T22:39:45.803367Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pickle\n","import networkx as nx\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","from tqdm import tqdm\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.amp import GradScaler"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:48.066662Z","iopub.status.busy":"2025-01-20T22:39:48.066097Z","iopub.status.idle":"2025-01-20T22:39:48.071282Z","shell.execute_reply":"2025-01-20T22:39:48.070579Z","shell.execute_reply.started":"2025-01-20T22:39:48.066639Z"},"trusted":true},"outputs":[],"source":["class TSPDataset(torch.utils.data.Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        G, opt_tour = self.data[idx]\n","        n = G.number_of_nodes()\n","        attr = nx.get_node_attributes(G, 'pos')\n","        X = []\n","        for i in range(n):\n","            X.append(torch.tensor(attr[i], dtype=torch.float32))\n","\n","        return torch.stack(X), torch.tensor(opt_tour)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:48.072639Z","iopub.status.busy":"2025-01-20T22:39:48.072413Z","iopub.status.idle":"2025-01-20T22:39:48.086797Z","shell.execute_reply":"2025-01-20T22:39:48.086072Z","shell.execute_reply.started":"2025-01-20T22:39:48.072620Z"},"trusted":true},"outputs":[],"source":["def create_dataloaders(train_path, val_path, test_path, batch_size=32):\n","    \"\"\"\n","    Create DataLoader objects for training, validation, and testing.\n","    Args:\n","        train_path (str): Path to training data pickle file.\n","        val_path (str): Path to validation data pickle file.\n","        test_path (str): Path to test data pickle file.\n","        batch_size (int): Batch size for the dataloaders.\n","    Returns:\n","        tuple: (train_loader, val_loader, test_loader)\n","    \"\"\"\n","    try:\n","        # Use only one argument for TSPDataset\n","        #train_dataset = TSPDataset('/kaggle/input/data-t/data/train_20_DLL_ass4.pkl')\n","        X = pickle.load(open(train_path, 'rb'))\n","        train_dataset = TSPDataset(X)\n","        X = pickle.load(open(val_path, 'rb'))\n","        val_dataset = TSPDataset(X)\n","        X = pickle.load(open(test_path, 'rb'))\n","        test_dataset = TSPDataset(X)\n","        #val_dataset = TSPDataset('/kaggle/input/data-t/data/valid_20_DLL_ass4.pkl')\n","        #test_dataset = TSPDataset('/kaggle/input/data-t/data/test_20_DLL_ass4.pkl')\n","        \n","        train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=batch_size,\n","            shuffle=True,\n","            num_workers=0,  # Changed to 0 to avoid potential multiprocessing issues\n","            pin_memory=True\n","        )\n","        \n","        val_loader = DataLoader(\n","            val_dataset,\n","            batch_size=batch_size,\n","            shuffle=False,\n","            num_workers=0,\n","            pin_memory=True\n","        )\n","        \n","        test_loader = DataLoader(\n","            test_dataset,\n","            batch_size=batch_size,\n","            shuffle=False,\n","            num_workers=0,\n","            pin_memory=True\n","        )\n","        \n","        return train_loader, val_loader, test_loader\n","    \n","    except Exception as e:\n","        print(f\"Error creating dataloaders: {str(e)}\")\n","        raise\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:48.087964Z","iopub.status.busy":"2025-01-20T22:39:48.087631Z","iopub.status.idle":"2025-01-20T22:39:48.107251Z","shell.execute_reply":"2025-01-20T22:39:48.106582Z","shell.execute_reply.started":"2025-01-20T22:39:48.087935Z"},"trusted":true},"outputs":[],"source":["# Cell 3: Positional Encoding\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        \n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        \n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        \n","        self.register_buffer('pe', pe)\n","        \n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1)]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:48.108291Z","iopub.status.busy":"2025-01-20T22:39:48.108063Z","iopub.status.idle":"2025-01-20T22:39:48.128003Z","shell.execute_reply":"2025-01-20T22:39:48.127241Z","shell.execute_reply.started":"2025-01-20T22:39:48.108268Z"},"trusted":true},"outputs":[],"source":["# Cell 4: Transformer Model\n","class TSPTransformer(nn.Module):\n","    def __init__(self, d_model=128, nhead=8, num_encoder_layers=6, num_decoder_layers=6, n_nodes=20):\n","        super().__init__()\n","        self.d_model = d_model\n","        \n","        # Input embedding for node coordinates (2 -> d_model)\n","        self.input_embedding = nn.Linear(2, d_model)\n","        \n","        # Node embedding for decoder (n_nodes -> d_model)\n","        self.node_embedding = nn.Embedding(n_nodes, d_model)\n","        \n","        # Positional encoding for decoder\n","        self.pos_encoder = PositionalEncoding(d_model)\n","        \n","        # Transformer components\n","        self.transformer = nn.Transformer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            num_encoder_layers=num_encoder_layers,\n","            num_decoder_layers=num_decoder_layers,\n","            batch_first=True\n","        )\n","        \n","        # Output layer\n","        self.out = nn.Linear(d_model, n_nodes)\n","        \n","    def create_mask(self, size):\n","        mask = torch.triu(torch.ones(size, size), diagonal=1).bool()\n","        return mask\n","    \n","    def forward(self, x, y):\n","        # Encoder\n","        enc_input = self.input_embedding(x)\n","        \n","        # Decoder\n","        dec_input = self.node_embedding(y)\n","        dec_input = self.pos_encoder(dec_input)\n","        \n","        # Create causal mask for decoder\n","        tgt_mask = self.create_mask(y.size(1)).to(x.device)\n","        \n","        # Run through transformer\n","        out = self.transformer(\n","            enc_input, \n","            dec_input,\n","            tgt_mask=tgt_mask\n","        )\n","        \n","        return self.out(out)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:48.128932Z","iopub.status.busy":"2025-01-20T22:39:48.128705Z","iopub.status.idle":"2025-01-20T22:39:48.143141Z","shell.execute_reply":"2025-01-20T22:39:48.142463Z","shell.execute_reply.started":"2025-01-20T22:39:48.128912Z"},"trusted":true},"outputs":[],"source":["# Cell 5: Evaluation Functions\n","from networkx.algorithms.approximation import greedy_tsp\n","\n","def tour_length(G, tour):\n","    \"\"\"\n","    Compute the length of a tour. A tour is a list having elements 0 and -1 equal\n","    \"\"\"\n","    n = len(tour) - 1\n","    assert tour[0] == tour[-1], \"Not valid tour\"\n","    estimated = 0\n","    for i in range(n):\n","        estimated += G[tour[i]][tour[i + 1]]['weight']\n","    return estimated\n","\n","def greedy_algorithm(G):\n","    \"\"\"\n","    Run the value of the greedy approximation algorithm on graph G\n","    \"\"\"\n","    return tour_length(G, greedy_tsp(G, weight='weight'))\n","\n","def random_tour(G, seed=42):\n","    \"\"\"\n","    Return the value of a random tour\n","    \"\"\"\n","    np.random.seed(seed)\n","    n = G.number_of_nodes()\n","    tour = [0]\n","    for i in range(1, n):\n","        next_node = np.random.choice([j for j in range(n) if j not in tour])\n","        tour.append(next_node)\n","    tour.append(0)\n","    return tour_length(G, tour)\n","\n","def transformer_tsp(G, model, DEVICE='cpu'):\n","    \"\"\"\n","    Evaluate your (trained) model on G\n","    \"\"\"\n","    model.eval()\n","    n = G.number_of_nodes()\n","    \n","    # Get node coordinates\n","    attr = nx.get_node_attributes(G, 'pos')\n","    x = []\n","    for i in range(n):\n","        x.append(torch.tensor(attr[i], dtype=torch.float32))\n","\n","    # From list of tensors to tensor\n","    x = torch.stack(x)    # This may be not needed\n","\n","    tour = [0]\n","    y = torch.tensor(tour, dtype=torch.long)\n","    x = x.to(DEVICE).unsqueeze(0)\n","    y = y.to(DEVICE).unsqueeze(0)\n","    \n","    with torch.no_grad():\n","        out = model(x, y)\n","        \n","        while len(tour) < n:\n","            _, idx = torch.topk(out, n, dim=2)\n","            for i in range(n):\n","                if idx[0, 0, i] not in tour:\n","                    tour.append(idx[0, 0, i].item())\n","                    break\n","            y = torch.tensor(tour).to(DEVICE).unsqueeze(0)\n","            out = model(x, y)\n","    \n","    tour = tour + [0]  # Complete the cycle\n","    return tour_length(G, tour)\n","\n","def gap(G, model=None, model_GA=None, random_seed=42, device='cpu'):\n","    \"\"\"\n","    Compute the gap between the optimal solution on graph G and all the analyzed methods\n","    \"\"\"\n","    # Optimal value (hard-coded in the graph)\n","    TSP = sum([G[i][j]['weight']*G[i][j]['tour'] for (i, j) in G.edges()]) # Optimal\n","\n","    # Gaps dictionary\n","    gaps = {'greedy': 0, 'random': 0, 'transformer_tsp': 0, 'transformer_tsp_acc_grad': 0}\n","    gaps['greedy'] = 100 * (greedy_algorithm(G) - TSP) / TSP\n","    gaps['random'] = 100 * (random_tour(G, random_seed) - TSP) / TSP\n","    \n","    if model is not None:\n","        gaps['transformer_tsp'] = 100 * (transformer_tsp(G, model, DEVICE=device) - TSP) / TSP\n","    else:\n","        gaps['transformer_tsp'] = float('inf')\n","        \n","    if model_GA is not None:\n","        gaps['transformer_tsp_acc_grad'] = 100 * (transformer_tsp(G, model_GA, DEVICE=device) - TSP) / TSP\n","    else:\n","        gaps['transformer_tsp_acc_grad'] = float('inf')\n","    return gaps"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:48.145474Z","iopub.status.busy":"2025-01-20T22:39:48.145200Z","iopub.status.idle":"2025-01-20T22:39:48.164121Z","shell.execute_reply":"2025-01-20T22:39:48.163389Z","shell.execute_reply.started":"2025-01-20T22:39:48.145446Z"},"trusted":true},"outputs":[],"source":["# Cell 5: Training Functions\n","def train_epoch(model, train_loader, optimizer, criterion, device, accumulation_steps=1):\n","    model.train()\n","    total_loss = 0\n","    optimizer.zero_grad()\n","    \n","    for i, (x, y) in enumerate(tqdm(train_loader)):\n","        x, y = x.to(device), y.to(device)\n","        \n","        # Shift y for teacher forcing\n","        decoder_input = y[:, :-1]\n","        target = y[:, 1:]\n","        \n","        # Forward pass\n","        output = model(x, decoder_input)\n","        loss = criterion(output.reshape(-1, output.size(-1)), target.reshape(-1))\n","        \n","        # Scale loss for gradient accumulation\n","        loss = loss / accumulation_steps\n","        loss.backward()\n","        \n","        if (i + 1) % accumulation_steps == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            \n","        total_loss += loss.item() * accumulation_steps\n","        \n","    return total_loss / len(train_loader)\n","\n","def validate(model, val_loader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    \n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            x, y = x.to(device), y.to(device)\n","            decoder_input = y[:, :-1]\n","            target = y[:, 1:]\n","            \n","            output = model(x, decoder_input)\n","            loss = criterion(output.reshape(-1, output.size(-1)), target.reshape(-1))\n","            total_loss += loss.item()\n","            \n","    return total_loss / len(val_loader)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:39:48.165373Z","iopub.status.busy":"2025-01-20T22:39:48.165056Z","iopub.status.idle":"2025-01-20T22:40:08.996751Z","shell.execute_reply":"2025-01-20T22:40:08.995894Z","shell.execute_reply.started":"2025-01-20T22:39:48.165349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]}],"source":["# Cell 6: Training Setup and Execution\n","# Set device\n","\n","\n","\n","scaler = GradScaler(device='cuda')\n","scaler_accum = GradScaler(device='cuda')\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","try:\n","    # Create dataloaders\n","    train_loader, val_loader, test_loader = create_dataloaders(\n","        '/kaggle/input/data-t/data/train_20_DLL_ass4.pkl',\n","        '/kaggle/input/data-t/data/valid_20_DLL_ass4.pkl',\n","        '/kaggle/input/data-t/data/test_20_DLL_ass4.pkl',\n","        batch_size=32\n","    )\n","    \n","    # Initialize model and training components\n","    model = TSPTransformer().to(device)\n","    optimizer = optim.AdamW(model.parameters(), lr=0.0001,weight_decay=1e-5)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # Training parameters\n","    n_epochs = 10  # Adjust based on your time budget\n","    accumulation_steps = 4  # For gradient accumulation training\n","\n","    # Learning rate schedulers\n","    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n","\n","\n","    # Gradient scaler for mixed precision training\n","    scaler = GradScaler()\n","    scaler_accum = GradScaler()\n","\n","    # Enable cuDNN benchmarking for potentially faster training\n","    torch.backends.cudnn.benchmark = True\n","\n","\n","    \n","\n","    # Training history\n","    train_losses = []\n","    val_losses = []\n","\n","   \n","except Exception as e:\n","    print(f\"An error occurred during training setup/execution: {str(e)}\")\n","    raise"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:40:08.998230Z","iopub.status.busy":"2025-01-20T22:40:08.997686Z","iopub.status.idle":"2025-01-20T22:40:09.006090Z","shell.execute_reply":"2025-01-20T22:40:09.005350Z","shell.execute_reply.started":"2025-01-20T22:40:08.998192Z"},"trusted":true},"outputs":[],"source":["#Train model definition\n","\n","\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, device, n_epochs, accumulation_steps=1):\n","    model.to(device)\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(n_epochs):\n","        model.train()\n","        total_loss = 0\n","        optimizer.zero_grad()  # Reset gradients at the start of each epoch\n","\n","        for i, (x, y) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\")):\n","            x, y = x.to(device), y.to(device)\n","            output = model(x, y[:, :-1])  # Exclude last element of y for input\n","            loss = criterion(output.view(-1, output.size(-1)), y[:, 1:].contiguous().view(-1))\n","            \n","            # Normalize loss to account for batch accumulation\n","            loss = loss / accumulation_steps\n","            loss.backward()\n","            \n","            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n","                optimizer.step()\n","                optimizer.zero_grad()\n","            \n","            total_loss += loss.item() * accumulation_steps\n","\n","        train_loss = total_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                x, y = x.to(device), y.to(device)\n","                output = model(x, y[:, :-1])\n","                loss = criterion(output.view(-1, output.size(-1)), y[:, 1:].contiguous().view(-1))\n","                val_loss += loss.item()\n","        \n","        val_loss /= len(val_loader)\n","        val_losses.append(val_loss)\n","\n","        print(f'Epoch {epoch+1}/{n_epochs}')\n","        print(f'Training Loss: {train_loss:.4f}')\n","        print(f'Validation Loss: {val_loss:.4f}')\n","        print('-' * 40)\n","\n","    return model, train_losses, val_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-01-20T22:40:09.007229Z","iopub.status.busy":"2025-01-20T22:40:09.006928Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting standard training...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/10: 100%|██████████| 1563/1563 [00:59<00:00, 26.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","Training Loss: 2.1816\n","Validation Loss: 2.0325\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/10: 100%|██████████| 1563/1563 [00:59<00:00, 26.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/10\n","Training Loss: 2.0551\n","Validation Loss: 2.0119\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/10:   1%|          | 18/1563 [00:00<00:57, 26.81it/s]"]}],"source":["# Standard Training \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = TSPTransformer().to(device)\n","model_accum = TSPTransformer().to(device)\n","optimizer = optim.AdamW(model.parameters(), lr=0.0001,weight_decay=1e-5)\n","optimizer_accum = optim.AdamW(model_accum.parameters(), lr=0.0001,weight_decay=1e-5)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Assuming you have already created your DataLoaders\n","\n","\n","n_epochs = 10\n","accumulation_steps = 4\n","\n","# Learning rate schedulers\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n","\n","\n","    # Gradient scaler for mixed precision training\n","scaler = GradScaler()\n","scaler_accum = GradScaler()\n","\n","    # Enable cuDNN benchmarking for potentially faster training\n","torch.backends.cudnn.benchmark = True\n","\n","\n","\n","\n","\n","\n","\n","# Standard training\n","print(\"Starting standard training...\")\n","model, train_losses, val_losses = train_model(\n","    model, train_loader, val_loader, criterion, optimizer, device, n_epochs\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","# Training with gradient accumulation\n","print(\"Starting training with gradient accumulation...\")\n","model_accum, train_losses_accum, val_losses_accum = train_model(\n","    model_accum, train_loader, val_loader, criterion, optimizer_accum, device, n_epochs, accumulation_steps\n",")\n","\n","# Save models and training history\n","torch.save(model.state_dict(), 'model_standard.pth')\n","torch.save(model_accum.state_dict(), 'model_accum.pth')\n","torch.save({\n","    'train_losses': train_losses,\n","    'val_losses': val_losses,\n","    'train_losses_accum': train_losses_accum,\n","    'val_losses_accum': val_losses_accum\n","}, 'training_history.pth')\n","\n","# Evaluation and plotting\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def plot_losses(train_losses, val_losses, train_losses_accum, val_losses_accum):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n","    \n","    # Standard training plot\n","    ax1.plot(train_losses, label='Training Loss')\n","    ax1.plot(val_losses, label='Validation Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.set_title('Standard Training Losses')\n","    ax1.legend()\n","    ax1.grid(True)\n","    \n","    # Gradient accumulation training plot\n","    ax2.plot(train_losses_accum, label='Training Loss')\n","    ax2.plot(val_losses_accum, label='Validation Loss')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Loss')\n","    ax2.set_title('Gradient Accumulation Training Losses')\n","    ax2.legend()\n","    ax2.grid(True)\n","    \n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","    # Plot training history\n","plot_losses(train_losses, val_losses, train_losses_accum, val_losses_accum)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Testing\n","\n","def evaluate_all_methods(test_dataset, model_standard, model_accum, device):\n","    all_gaps = []\n","    for data in tqdm(test_dataset.data, desc=\"Evaluating instances\"):\n","        # If G is part of a tuple, unpack it\n","        if isinstance(data, tuple):\n","            G = data[0]  # Assuming the graph is the first element\n","        else:\n","            G = data  # Otherwise, use data as-is\n","        \n","        gaps = gap(G, model_standard, model_accum, device=device)\n","        all_gaps.append(gaps)\n","    \n","    # Organize results by method\n","    method_gaps = {\n","        'random': [g['random'] for g in all_gaps],\n","        'greedy': [g['greedy'] for g in all_gaps],\n","        'transformer_tsp': [g['transformer_tsp'] for g in all_gaps],\n","        'transformer_tsp_acc_grad': [g['transformer_tsp_acc_grad'] for g in all_gaps]\n","    }\n","    \n","    return method_gaps\n","\n","def plot_gap_comparison(method_gaps):\n","    plt.figure(figsize=(10, 6))\n","    plt.boxplot(method_gaps.values(), labels=method_gaps.keys())\n","    plt.ylabel('Optimality Gap (%)')\n","    plt.title('Performance Comparison of Different Methods')\n","    plt.xticks(rotation=45)\n","    plt.grid(True)\n","    plt.show()\n","\n","# Plot training history\n","\n","\n","try:\n","    # Evaluate all methods on test set\n","    method_gaps = evaluate_all_methods(test_loader.dataset, model, model_accum, device)\n","    plot_gap_comparison(method_gaps)\n","\n","    # Print summary statistics\n","    print(\"\\nGap Statistics:\")\n","    for method, gaps in method_gaps.items():\n","        print(f\"\\n{method}:\")\n","        print(f\"Mean gap: {np.mean(gaps):.2f}%\")\n","        print(f\"Median gap: {np.median(gaps):.2f}%\")\n","        print(f\"Std gap: {np.std(gaps):.2f}%\")\n","except Exception as e:\n","    print(f\"An error occurred during evaluation: {str(e)}\")\n","    raise\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6471556,"sourceId":10454300,"sourceType":"datasetVersion"}],"dockerImageVersionId":30822,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
